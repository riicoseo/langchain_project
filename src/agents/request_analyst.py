from langchain_core.prompts import ChatPromptTemplate

from pydantic import BaseModel, Field

from typing_extensions import TypedDict
from typing import Annotated, Literal



class FinanceGate(BaseModel):
    label: str = Field(description="ê²½ì œ ê¸ˆìœµ ê´€ë ¨ ì—¬ë¶€ label.")

def request_analysis(state, llm)-> Literal["finance", "not_finance"]:

    """
    Args:
        state (dict) : The current graph state
    
    Returns:
        state (dict) : 

    """
    print('='*10,"Request Analysis THINKING START!",'='*10)
    question = state['question']

    # define supervisor prompt
    request_analysis_prompt = ChatPromptTemplate.from_template(
        """
        ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ ë˜ëŠ” ìš”ì²­ì´ "ê²½ì œ, ê¸ˆìœµ ê´€ë ¨"ì´ì§€ íŒë³„í•˜ëŠ” ë¶„ë¥˜ê¸° ì…ë‹ˆë‹¤.
        
        íŒë‹¨ ê¸°ì¤€:
        - ê²½ì œ, ê¸ˆìœµ ê´€ë ¨(`finance`) ì˜ˆì‹œ : ì£¼ì‹ETF/ì±„ê¶Œ/íŒŒìƒìƒí’ˆ, í™˜ìœ¨/ê¸ˆë¦¬/ì¸í”Œë ˆì´ì…˜/ê±°ì‹œê²½ì œ, ê¸°ì—… ì‹¤ì /ë°¸ë¥˜ì—ì´ì…˜(Market Cap, PER/PBR/EV/EBITDA ë“±), ì¬ë¬´ì œí‘œ/íšŒê³„, ê°œì¸ì¬ë¬´(ì˜ˆì‚°/ì €ì¶•/ëŒ€ì¶œ/ì„¸ê¸ˆ), ì•”í˜¸ìì‚°ì˜ ì‹œì„¸/ê±°ë˜/í† í° ì´ì½”ë…¸ë¯¸(íˆ¬ì ë§¥ë½), ê¸ˆìœµ/ê·œì œ/ì •ì±…/ê³µì‹œ/ë‰´ìŠ¤.
        - ë¹„ê´€ë ¨(`not_finance`) ì˜ˆì‹œ : ë‚ ì”¨/ì—¬í–‰/ìš”ë¦¬/ìŠ¤í¬ì¸ /ê²Œì„/ì¼ìƒ ëŒ€í™”, ì¼ë°˜ IT/í”„ë¡œê·¸ë˜ë°(ê¸ˆìœµ ë§¥ë½ ì—†ìŒ), ì—­ì‚¬/ì˜ˆìˆ /ë¬¸í™”, ë¹„ì¬ë¬´ì  ê¸°ì—… ì†Œê°œ(ì—°í˜/ì±„ìš© ë“±ë§Œ).
        
        ì—£ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬:
        - ê¸°ìˆ /ë°ì´í„°/AI ì§ˆë¬¸ì´ë¼ë„ "íˆ¬ì ì˜ì‚¬ê²°ì •/ì‹œì¥/ì¬ë¬´ ì§€í‘œ/ê±°ì‹œê²½ì œ"ì™€ ì§ì ‘ ì—°ê²°ë˜ë©´ `finance`.
        - ì•”í˜¸í™”í/ë¸”ë¡ì²´ì¸ ê¸°ìˆ  ìì²´ëŠ” `not_finance`ì´ì§€ë§Œ, ê°€ê²©/íˆ¬ì/ê±°ë˜/ì‹œì¥ ë™í–¥ì„ ë¬»ëŠ”ë‹¤ë©´ `finance`.
        - ì§ˆë¬¸ì´ ëª¨í˜¸í•˜ë©´ ì‚¬ìš©ì ì˜ë„ê°€ ê¸ˆìœµì¼ ê°€ëŠ¥ì„±ì´ ìˆëŠ”ì§€ ë³´ìˆ˜ì ìœ¼ë¡œ íŒë‹¨í•˜ë˜, ê·¼ê±°ê°€ ë¶€ì¡±í•˜ë©´ `not_finance`

        ì¶œë ¥ì€ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì‹­ì‹œì˜¤. ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ì—¬ë¶„ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

        ì‚¬ìš©ì ì§ˆë¬¸:
        {question}
        """
    )
    chain = request_analysis_prompt | llm.with_structured_output(FinanceGate)
    result = chain.invoke({"question": question})
    print(f"Question status : {result.label}")

    if result.label == "not_finance":
        return {"generate" : "ì €ëŠ” ê²½ì œ, ê¸ˆìœµê´€ë ¨ ì •ë³´ë¥¼ í†µí•´ ì „ë¬¸ì ìœ¼ë¡œ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë„ì™€ë“œë¦¬ëŠ” AIì…ë‹ˆë‹¤!\nì£¼ì‹, í™˜ìœ¨, ê¸°ì—… ë¶„ì„ ë“± ê¸ˆìœµ ê´€ë ¨ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë‹µë³€ ë„ì™€ ë“œë¦´ê²Œìš” ğŸ˜„",
                'label' : "not_finance"}
    return {"label" : "finance"}


if __name__ == "__main__":
    from dotenv import load_dotenv
    from langchain_upstage import ChatUpstage

    # í™˜ê²½ë³€ìˆ˜ load
    load_dotenv()
    # llm í˜¸ì¶œ ë° ì •ì˜
    llm = ChatUpstage(model="solar-pro")


    # ì§ˆë¬¸ ì˜ˆì œ ì •ì˜
    input1 = {"question" : "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?"}
    input2 = {"question" : "AIê°€ ë­ì•¼ ?"}
    input3 = {"question" : "AI ì‹œì¥ íˆ¬ì ê·œëª¨ê°€ ì–´ë–»ê²Œ ë¼ ?"}

    # request_analysis ì‹¤í—˜
    example1 = request_analysis(input1, llm)
    example2 = request_analysis(input2, llm)
    example3 = request_analysis(input3, llm)

    # request_analysis ì‹¤í—˜
    print(f"Question 1 : {input1['question']} \nAnswer 1 : {example1.get('generate', 'finance')}")
    print(f"Question 2 : {input2['question']} \nAnswer 2 : {example2.get('generate', 'finance')}")
    print(f"Question 3 : {input3['question']} \nAnswer 3 : {example3.get('generate', 'finance')}")